{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11dea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (semantic_vocab_embeddings): Embedding(4115, 512)\n",
       "  (positional_embeddings): Embedding(256, 512)\n",
       "  (decoder_blocks): ModuleList(\n",
       "    (0-7): 8 x DecoderBlock(\n",
       "      (self_attention): SelfAttention(\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (W_Q): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (W_K): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (W_V): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (W): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=512, out_features=4115, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from diyt.tokenizer import SimpleTokenizer\n",
    "from diyt.model import Transformer, ModelConfig\n",
    "from diyt.paths import ASSETS_DIR\n",
    "\n",
    "tokenizer = SimpleTokenizer.load(ASSETS_DIR / \"hp\" / \"tokenizer.json\")\n",
    "checkpoint = torch.load(ASSETS_DIR / \"hp\" / \"model_checkpoints\" / \"checkpoint_200.pth\")\n",
    "\n",
    "model_config = ModelConfig.model_validate(checkpoint[\"model_config\"])\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size, **model_config.model_dump())\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f555334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from diyt.paths import DATA_DIR\n",
    "\n",
    "with open(DATA_DIR / \"harry_potter\" / \"train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f596955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much . They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense . <eos> Harry looked up at the giant . <eos> The giant chuckled darkly . <eos> The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it . They didn't think they could bear it if anyone found out about the Potters . Mrs . Potter was Mrs . Dursley's sister, but they hadn't met for several years; in fact,\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly\"\n",
    "num_gen = 100\n",
    "\n",
    "for _ in range(num_gen):\n",
    "    encoded = tokenizer([text], max_seq_length=model_config.context_length)\n",
    "    next_idx = sum(encoded.attention_mask[0])\n",
    "    logits = model(**encoded.model_dump())\n",
    "    next_token_id = logits[0, next_idx - 1].argmax(dim=-1)\n",
    "    next_token = tokenizer.decode([next_token_id])\n",
    "    text += \" \" + next_token\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d523a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
